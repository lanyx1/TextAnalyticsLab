{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d34e2e74-a52c-446f-845d-1f6b2e5d6ecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x92 in position 662: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[0;32m      6\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x92 in position 662: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"Review.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1454cbb-8a56-47bc-9e83-5dce3f8c699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           Review\n",
      "0   The product arrived on time. Packaging was great, and the quality is amazing!\n",
      "1                                        THIS PRODUCT IS JUST AMAZING! I LOVE IT.\n",
      "2     I bought this phone for $799, and it has a 120Hz display. Totally worth it!\n",
      "3                         Wow!!! This product is awesome... but a bit expensive??\n",
      "4                                             The laptop works perfectly fine.   \n",
      "5    Check out the full product details here: https://example.com/product-details\n",
      "6         <div><h2>Great Purchase!</h2><p>I am happy with this product.</p></div>\n",
      "7                The battry life is excelent, but the chargin cable is too short.\n",
      "8                       I can't believe it's so good! Didn't expect such quality.\n",
      "9                   Love this product! ???? Fast delivery ??, amazing quality! ??\n",
      "10                       TBH, I wasnt expecting much, but OMG, this is awesome!!\n",
      "11                          This is the best product I have ever used in my life!\n",
      "12  The shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"Review.csv\"\n",
    "df = pd.read_csv(file_path, encoding=\"ISO-8859-1\")  # or encoding=\"latin1\"\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d54bb6c-cb56-4e05-a725-d89990002542",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'covert_to_lowercase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_lowercase\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m----> 4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlowercased\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(covert_to_lowercase)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'covert_to_lowercase' is not defined"
     ]
    }
   ],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "df[\"lowercased\"] = df[\"Review\"].apply(covert_to_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19f1a235-aaeb-4f06-b450-74321e332988",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'covert_to_lowercase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_lowercase\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m----> 4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlowercased\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(covert_to_lowercase)\n\u001b[0;32m      6\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlowercased\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'covert_to_lowercase' is not defined"
     ]
    }
   ],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "df[\"lowercased\"] = df[\"Review\"].apply(covert_to_lowercase)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"lowercased\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8369c4c-ea8c-476f-afc1-2499383f582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5      check out the full product details here: https://example.com/product-details\n",
      "6           <div><h2>great purchase!</h2><p>i am happy with this product.</p></div>\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: lowercased, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "df[\"lowercased\"] = df[\"Review\"].apply(convert_to_lowercase)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"lowercased\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cdcad7e-9f23-468c-92ad-fc2f09106a03",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sub() missing 1 required positional argument: 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_urls\u001b[39m(text):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+|www\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m----> 6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murls_removed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlowercased\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(remove_urls)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36mremove_urls\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_urls\u001b[39m(text):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+|www\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n",
      "\u001b[1;31mTypeError\u001b[0m: sub() missing 1 required positional argument: 'string'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\s+|www\\s+', text)\n",
    "\n",
    "df[\"urls_removed\"] = df[\"lowercased\"].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48b37799-cd05-428e-8076-e64d49d197d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sub() missing 1 required positional argument: 'string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_urls\u001b[39m(text):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+|www\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m----> 6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murls_removed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlowercased\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(remove_urls)\n\u001b[0;32m      8\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murls_removed\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m, in \u001b[0;36mremove_urls\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_urls\u001b[39m(text):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+|www\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n",
      "\u001b[1;31mTypeError\u001b[0m: sub() missing 1 required positional argument: 'string'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\s+|www\\s+', text)\n",
    "\n",
    "df[\"urls_removed\"] = df[\"lowercased\"].apply(remove_urls)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"urls_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8365ea48-cbe5-4ed3-bbdd-cfc71916fa1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5      check out the full product details here: https://example.com/product-details\n",
      "6           <div><h2>great purchase!</h2><p>i am happy with this product.</p></div>\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: urls_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\s+|www\\s+', '', text)\n",
    "\n",
    "df[\"urls_removed\"] = df[\"lowercased\"].apply(remove_urls)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"urls_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5329be8-e84b-44f4-8c9b-98ebd485345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c9640c-681b-473f-bba2-701fb7503695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0713442-3c37-4f15-a239-c49b3708015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5      check out the full product details here: https://example.com/product-details\n",
      "6                                      great purchase!i am happy with this product.\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: html_removed, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Username\\AppData\\Local\\Temp\\ipykernel_35032\\201357161.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "df[\"html_removed\"] = df[\"urls_removed\"].apply(remove_html_tags)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"html_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "583d1eeb-9b16-455f-a46e-1167b846cf13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01memoji\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_emojis\u001b[39m(text):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m emoji\u001b[38;5;241m.\u001b[39mreplace_emoji(text, replace\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace= \"\")\n",
    "\n",
    "df[\"emoji_removed\"] = df[\"html_removed\"].apply(remove_emojis)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"emojis_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67b2fa64-f655-482d-892f-2044595b0279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 590.6/590.6 kB 5.2 MB/s eta 0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1a55cc4-3c6d-4232-b1ea-a383bfc62e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5      check out the full product details here: https://example.com/product-details\n",
      "6                                      great purchase!i am happy with this product.\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10                         tbh, i wasnt expecting much, but omg, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: emoji_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "def remove_emojis(text):\n",
    "    return emoji.replace_emoji(text, replace=\"\")  # Replaces emojis with an empty string\n",
    "\n",
    "df[\"emoji_removed\"] = df[\"html_removed\"].apply(remove_emojis)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"emoji_removed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bb94353-5d82-44d0-8be1-2c8dd8f88ef9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4227719438.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    escaped_slang_words =\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "slang_dict = {\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\", \n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"ikr\": \"I know right\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"bff\": \"best friend forever\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"rofl\": \"rolling on the floor laughing\"\n",
    "}\n",
    "\n",
    "def replace_slang(text):\n",
    "    escaped_slang_words =  \n",
    "    \n",
    "    for word in slang_dict.keys():\n",
    "        escaped_word = re.escape(word)\n",
    "        escaped_slang_words.append(escaped_word)\n",
    "\n",
    "    slang_pattern =r'\\b(' + '|'.join(escaped_slang_words) + r')\\b'\n",
    "\n",
    "    def replace_match(match):\n",
    "        slang_word = match.group(0)\n",
    "        return slang_dict[slang_word.lower()]\n",
    "\n",
    "    replaced_text = re.sub(slang_pattern, replace_match, text, flags = re.IGNORECASE)\n",
    "\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b8fa4b3-7d50-441f-b7ac-c3c5dea493ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (634296553.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    escaped_slang_words =\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "slang_dict = {\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\", \n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"ikr\": \"I know right\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"bff\": \"best friend forever\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"rofl\": \"rolling on the floor laughing\"\n",
    "}\n",
    "\n",
    "def replace_slang(text):\n",
    "    escaped_slang_words =  \n",
    "    \n",
    "    for word in slang_dict.keys():\n",
    "        escaped_word = re.escape(word)\n",
    "        escaped_slang_words.append(escaped_word)\n",
    "\n",
    "    slang_pattern =r'\\b(' + '|'.join(escaped_slang_words) + r')\\b'\n",
    "\n",
    "    def replace_match(match):\n",
    "        slang_word = match.group(0)\n",
    "        return slang_dict[slang_word.lower()]\n",
    "\n",
    "    replaced_text = re.sub(slang_pattern, replace_match, text, flags = re.IGNORECASE)\n",
    "\n",
    "    return replaced_text\n",
    "\n",
    "    df[\"slangs_replaced\"] = df[\"emojis_removed\"].apply(replace_slang)\n",
    "\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(df[\"slangs_replaceed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adc6b23c-e693-4316-9540-b47b18003333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5      check out the full product details here: https://example.com/product-details\n",
      "6                                      great purchase!i am happy with this product.\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                         i can't believe it's so good! didn't expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10          to be honest, i wasnt expecting much, but oh my god, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: slangs_replaced, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "slang_dict = {\n",
    "    \"tbh\": \"to be honest\",\n",
    "    \"omg\": \"oh my god\",\n",
    "    \"lol\": \"laugh out loud\",\n",
    "    \"idk\": \"I don't know\",\n",
    "    \"brb\": \"be right back\",\n",
    "    \"btw\": \"by the way\",\n",
    "    \"imo\": \"in my opinion\", \n",
    "    \"smh\": \"shaking my head\",\n",
    "    \"fyi\": \"for your information\",\n",
    "    \"np\": \"no problem\",\n",
    "    \"ikr\": \"I know right\",\n",
    "    \"asap\": \"as soon as possible\",\n",
    "    \"bff\": \"best friend forever\",\n",
    "    \"gg\": \"good game\",\n",
    "    \"hmu\": \"hit me up\",\n",
    "    \"rofl\": \"rolling on the floor laughing\"\n",
    "}\n",
    "\n",
    "def replace_slang(text):\n",
    "    escaped_slang_words = []  # FIXED: Initialize list\n",
    "\n",
    "    for word in slang_dict.keys():\n",
    "        escaped_word = re.escape(word)\n",
    "        escaped_slang_words.append(escaped_word)\n",
    "\n",
    "    slang_pattern = r'\\b(' + '|'.join(escaped_slang_words) + r')\\b'\n",
    "\n",
    "    def replace_match(match):\n",
    "        slang_word = match.group(0)\n",
    "        return slang_dict[slang_word.lower()]\n",
    "\n",
    "    replaced_text = re.sub(slang_pattern, replace_match, text, flags=re.IGNORECASE)\n",
    "\n",
    "    return replaced_text\n",
    "\n",
    "df[\"slangs_replaced\"] = df[\"emoji_removed\"].apply(replace_slang)  # FIXED: Correct column name\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"slangs_replaced\"])  # FIXED: Correct column name in print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "751408f3-d67d-4cc8-a25a-9a777cc26d75",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m contraction \u001b[38;5;129;01min\u001b[39;00m contractions_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     52\u001b[0m     escaped_contractions \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mescape(contraction)\n\u001b[1;32m---> 53\u001b[0m     escaped_contractions\u001b[38;5;241m.\u001b[39mappend(escaped_contractions)\n\u001b[0;32m     55\u001b[0m joined_contractions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb(\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m joined_contractions \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     57\u001b[0m compiled_pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(contractions_pattern, flags \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mIGNORECASE)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "contractions_dict = {\n",
    "    \"wasn't\": \"was not\", \n",
    "    \"isn't\": \"is not\", \n",
    "    \"aren't\": \"are not\",\n",
    "    \"weren't\": \"were not\", \n",
    "    \"doesn't\": \"does not\", \n",
    "    \"don't\": \"do not\", \n",
    "    \"didn't\": \"did not\", \n",
    "    \"can't\": \"cannot\", \n",
    "    \"couldn't\": \"could not\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"wouldn't\": \"would not\", \n",
    "    \"won't\": \"will not\", \n",
    "    \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\", \n",
    "    \"hadn't\": \"had not\", \n",
    "    \"i'm\": \"i am\", \n",
    "    \"you're\": \"you are\", \n",
    "    \"he's\": \"he is\", \n",
    "    \"she's\": \"she is\", \n",
    "    \"it's\": \"it is\",\n",
    "    \"we're\": \"we are\", \n",
    "    \"they're\": \"they are\", \n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\", \n",
    "    \"i'd\": \"i would\", \n",
    "    \"you'd\": \"you would\", \n",
    "    \"he'd\": \"he would\", \n",
    "    \"she'd\": \"she would\",\n",
    "    \"we'd\": \"we would\", \n",
    "    \"they'd\": \"they would\", \n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\", \n",
    "    \"she'll\": \"she will\", \n",
    "    \"we'll\": \"we will\", \n",
    "    \"they'll\": \"they will\",\n",
    "    \"let's\": \"let us\", \n",
    "    \"that's\": \"that is\",\n",
    "    \"who's\": \"who is\", \n",
    "    \"what's\": \"what is\", \n",
    "    \"where's\": \"where is\", \n",
    "    \"when's\": \"when is\",\n",
    "    \"why's\": \"why is\"\n",
    "}\n",
    "\n",
    "escaped_contraction = []\n",
    "\n",
    "for contraction in contractions_dict.keys():\n",
    "    escaped_contractions = re.escape(contraction)\n",
    "    escaped_contractions.append(escaped_contractions)\n",
    "\n",
    "joined_contractions = r'\\b(' + joined_contractions + r')\\b'\n",
    "\n",
    "compiled_pattern = re.compile(contractions_pattern, flags = re.IGNORECASE)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    def replace_match(match):\n",
    "        matched_word = match.group(0)\n",
    "        lower_matched_word = matched_word.lower()\n",
    "        expanded_form = contractions_dict[lower_matched_word]\n",
    "        return expanded_form \n",
    "\n",
    "    expanded_text = compiled_pattern.sub(replace_match, text)\n",
    "\n",
    "    return expanded_text\n",
    "\n",
    "df[\"contractions_replaced\"] = df [\"slangs_replaced\"].apply(replace_contractions) \n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"contractions_replaced\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f858f5c-83bd-4df1-abf5-b6cb61610e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time. packaging was great, and the quality is amazing!\n",
      "1                                          this product is just amazing! i love it.\n",
      "2       i bought this phone for $799, and it has a 120hz display. totally worth it!\n",
      "3                           wow!!! this product is awesome... but a bit expensive??\n",
      "4                                               the laptop works perfectly fine.   \n",
      "5      check out the full product details here: https://example.com/product-details\n",
      "6                                      great purchase!i am happy with this product.\n",
      "7                  the battry life is excelent, but the chargin cable is too short.\n",
      "8                      i cannot believe it is so good! did not expect such quality.\n",
      "9                     love this product! ???? fast delivery ??, amazing quality! ??\n",
      "10          to be honest, i wasnt expecting much, but oh my god, this is awesome!!\n",
      "11                            this is the best product i have ever used in my life!\n",
      "12    the shoes were comfortable, fitting nicely, and worked perfectly for jogging.\n",
      "Name: contractions_replaced, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "contractions_dict = {\n",
    "    \"wasn't\": \"was not\", \"isn't\": \"is not\", \"aren't\": \"are not\",\n",
    "    \"weren't\": \"were not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \n",
    "    \"didn't\": \"did not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\n",
    "    \"shouldn't\": \"should not\", \"wouldn't\": \"would not\", \"won't\": \"will not\",\n",
    "    \"haven't\": \"have not\", \"hasn't\": \"has not\", \"hadn't\": \"had not\", \n",
    "    \"i'm\": \"i am\", \"you're\": \"you are\", \"he's\": \"he is\", \"she's\": \"she is\", \n",
    "    \"it's\": \"it is\", \"we're\": \"we are\", \"they're\": \"they are\", \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\", \"we've\": \"we have\", \"they've\": \"they have\", \n",
    "    \"i'd\": \"i would\", \"you'd\": \"you would\", \"he'd\": \"he would\", \"she'd\": \"she would\",\n",
    "    \"we'd\": \"we would\", \"they'd\": \"they would\", \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\", \"he'll\": \"he will\", \"she'll\": \"she will\", \n",
    "    \"we'll\": \"we will\", \"they'll\": \"they will\", \"let's\": \"let us\", \n",
    "    \"that's\": \"that is\", \"who's\": \"who is\", \"what's\": \"what is\", \n",
    "    \"where's\": \"where is\", \"when's\": \"when is\", \"why's\": \"why is\"\n",
    "}\n",
    "\n",
    "# **FIX: Store escaped contractions in a list**\n",
    "escaped_contractions = []\n",
    "\n",
    "for contraction in contractions_dict.keys():\n",
    "    escaped_contractions.append(re.escape(contraction))\n",
    "\n",
    "# **FIX: Join list into regex pattern**\n",
    "contractions_pattern = r'\\b(' + '|'.join(escaped_contractions) + r')\\b'\n",
    "compiled_pattern = re.compile(contractions_pattern, flags=re.IGNORECASE)\n",
    "\n",
    "def replace_contractions(text):\n",
    "    def replace_match(match):\n",
    "        matched_word = match.group(0)\n",
    "        lower_matched_word = matched_word.lower()\n",
    "        return contractions_dict[lower_matched_word]\n",
    "\n",
    "    return compiled_pattern.sub(replace_match, text)\n",
    "\n",
    "df[\"contractions_replaced\"] = df[\"slangs_replaced\"].apply(replace_contractions)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"contractions_replaced\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfad1fa6-7893-4892-909a-4eb4f90a9cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the first two maketrans arguments must have equal length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_punctuation\u001b[39m(text):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, string\u001b[38;5;241m.\u001b[39mpunctuation))\n\u001b[1;32m----> 6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpunctuations_removed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontractions_replaced\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(remove_punctuation)\n\u001b[0;32m      8\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpunctuations_removed\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m, in \u001b[0;36mremove_punctuation\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_punctuation\u001b[39m(text):\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, string\u001b[38;5;241m.\u001b[39mpunctuation))\n",
      "\u001b[1;31mValueError\u001b[0m: the first two maketrans arguments must have equal length"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\", string.punctuation))\n",
    "\n",
    "df[\"punctuations_removed\"]= df[\"contractions_replaced\"].apply(remove_punctuation)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"punctuations_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2e0307d-edb6-41e8-a59c-50ef4e9ad74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time packaging was great and the quality is amazing\n",
      "1                                         this product is just amazing i love it\n",
      "2        i bought this phone for 799 and it has a 120hz display totally worth it\n",
      "3                                wow this product is awesome but a bit expensive\n",
      "4                                             the laptop works perfectly fine   \n",
      "5          check out the full product details here httpsexamplecomproductdetails\n",
      "6                                     great purchasei am happy with this product\n",
      "7                 the battry life is excelent but the chargin cable is too short\n",
      "8                     i cannot believe it is so good did not expect such quality\n",
      "9                             love this product  fast delivery  amazing quality \n",
      "10            to be honest i wasnt expecting much but oh my god this is awesome\n",
      "11                          this is the best product i have ever used in my life\n",
      "12    the shoes were comfortable fitting nicely and worked perfectly for jogging\n",
      "Name: punctuations_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "df[\"punctuations_removed\"] = df[\"contractions_replaced\"].astype(str).apply(remove_punctuation)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"punctuations_removed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6f80c74-54d6-4e00-8155-d91439d20f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time packaging was great and the quality is amazing\n",
      "1                                         this product is just amazing i love it\n",
      "2              i bought this phone for  and it has a hz display totally worth it\n",
      "3                                wow this product is awesome but a bit expensive\n",
      "4                                             the laptop works perfectly fine   \n",
      "5          check out the full product details here httpsexamplecomproductdetails\n",
      "6                                     great purchasei am happy with this product\n",
      "7                 the battry life is excelent but the chargin cable is too short\n",
      "8                     i cannot believe it is so good did not expect such quality\n",
      "9                             love this product  fast delivery  amazing quality \n",
      "10            to be honest i wasnt expecting much but oh my god this is awesome\n",
      "11                          this is the best product i have ever used in my life\n",
      "12    the shoes were comfortable fitting nicely and worked perfectly for jogging\n",
      "Name: numbers_removed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def remove_numbers(text):\n",
    "    return re.sub(r'\\d+', \"\", text)\n",
    "\n",
    "df[\"numbers_removed\"] = df [\"punctuations_removed\"].apply(remove_numbers)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"numbers_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7df5c433-20a3-4f2b-b36f-60b2280d5282",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autocorrect'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mautocorrect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Speller\n\u001b[0;32m      3\u001b[0m spell \u001b[38;5;241m=\u001b[39m Speller(lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrect_spelling\u001b[39m(text):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'autocorrect'"
     ]
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "def correct_spelling(text):\n",
    "    return spell(text)\n",
    "\n",
    "df[\"spelling_corrected\"] = df[\"numbers_removed\"].apply(correct_spelling)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"spelling_corrected\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f1c8d92-4fa9-4373-9c94-08d0fca13b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
      "     ---------------------------------------- 0.0/622.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/622.8 kB ? eta -:--:--\n",
      "     ---------------- ----------------------- 262.1/622.8 kB ? eta -:--:--\n",
      "     ------------------------------ ----- 524.3/622.8 kB 799.2 kB/s eta 0:00:01\n",
      "     -------------------------------------- 622.8/622.8 kB 1.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py): started\n",
      "  Building wheel for autocorrect (setup.py): finished with status 'done'\n",
      "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622375 sha256=53460e22f9f868059eacd701eb7ffdd94f4412be857d2722ca46aa5fd80877a8\n",
      "  Stored in directory: c:\\users\\username\\appdata\\local\\pip\\cache\\wheels\\b6\\28\\c2\\9ddf8f57f871b55b6fd0ab99c887531fb9a66e5ff236b82aee\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "587c237d-cce5-457e-a639-e40b0422f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     the product arrived on time packaging was great and the quality is amazing\n",
      "1                                         this product is just amazing i love it\n",
      "2              i bought this phone for  and it has a hz display totally worth it\n",
      "3                                wow this product is awesome but a bit expensive\n",
      "4                                             the laptop works perfectly fine   \n",
      "5          check out the full product details here httpsexamplecomproductdetails\n",
      "6                                     great purchased am happy with this product\n",
      "7              the battery life is excellent but the charging cable is too short\n",
      "8                     i cannot believe it is so good did not expect such quality\n",
      "9                             love this product  fast delivery  amazing quality \n",
      "10            to be honest i wasnt expecting much but oh my god this is awesome\n",
      "11                          this is the best product i have ever used in my life\n",
      "12    the shoes were comfortable fitting nicely and worked perfectly for jogging\n",
      "Name: spelling_corrected, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from autocorrect import Speller\n",
    "\n",
    "spell = Speller(lang='en')\n",
    "\n",
    "def correct_spelling(text):\n",
    "    return spell(text)\n",
    "\n",
    "df[\"spelling_corrected\"] = df[\"numbers_removed\"].apply(correct_spelling)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"spelling_corrected\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15d7f778-1a3a-48e6-80e0-0d8f140c6997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Username\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          product arrived time packaging great quality amazing\n",
      "1                                          product amazing love\n",
      "2                         bought phone hz display totally worth\n",
      "3                             wow product awesome bit expensive\n",
      "4                                   laptop works perfectly fine\n",
      "5      check full product details httpsexamplecomproductdetails\n",
      "6                                 great purchased happy product\n",
      "7                   battery life excellent charging cable short\n",
      "8                            cannot believe good expect quality\n",
      "9                    love product fast delivery amazing quality\n",
      "10                  honest wasnt expecting much oh god awesome\n",
      "11                                  best product ever used life\n",
      "12    shoes comfortable fitting nicely worked perfectly jogging\n",
      "Name: stopwords_removed, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    filtered_words = []\n",
    "\n",
    "    for word in words:\n",
    "        lower_word = word.lower()\n",
    "        if lower_word not in stop_words:\n",
    "            filtered_words.append(word)\n",
    "\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df[\"stopwords_removed\"] = df[\"spelling_corrected\"].apply(remove_stopwords)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"stopwords_removed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fef2d0a-fa15-447e-b2f6-9bafa9d0f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "        words = text.split()\n",
    "        stemmed_words = [stemmer.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "\n",
    "    df[\"stemmed_words\"] = df[\"stopwords_removed\"].apply(stem_text)\n",
    "\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(df[\"stemmed_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "186a399f-3e32-43ca-821e-d248e5240787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "        words = text.split()\n",
    "        stemmed_words = [stemmer.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "\n",
    "    df[\"stemmed_words\"] = df[\"stopwords_removed\"].apply(stem_text)\n",
    "\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(df[\"stemmed_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc7ca26b-1014-440f-8f08-c67dcfa9bdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Username\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Username\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Username\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Username\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'isinstancce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m     lemmatized_words \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(word, get_wordnet_pos(tag)) \u001b[38;5;28;01mfor\u001b[39;00m word, tag \u001b[38;5;129;01min\u001b[39;00m pos_tags]\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lemmatized_words)\n\u001b[1;32m---> 40\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemmatized\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstopwords_removed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(lemmatize_text)\n\u001b[0;32m     42\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_colwidth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemmatized\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[29], line 32\u001b[0m, in \u001b[0;36mlemmatize_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize_text\u001b[39m(text):\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isinstancce(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m     words \u001b[38;5;241m=\u001b[39m word_tokenize(text)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'isinstancce' is not defined"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(nltk_tag):\n",
    "    if nltk_tag.startswith('j'):\n",
    "        return wordnet.ADJ\n",
    "\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "\n",
    "    elif nltk_taf.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    if not isinstancce(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    return \"\".join(lemmatized_words)\n",
    "\n",
    "df[\"lemmatized\"] = df[\"stopwords_removed\"].apply(lemmatize_text)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"lemmatized\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcc0cd02-0650-468a-b28a-2c2e55820b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Username\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Username\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Username\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Username\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         product arrive time packaging great quality amazing\n",
      "1                                          product amaze love\n",
      "2                          buy phone hz display totally worth\n",
      "3                           wow product awesome bit expensive\n",
      "4                                  laptop work perfectly fine\n",
      "5     check full product detail httpsexamplecomproductdetails\n",
      "6                                great purchase happy product\n",
      "7                   battery life excellent charge cable short\n",
      "8                         can not believe good expect quality\n",
      "9                  love product fast delivery amazing quality\n",
      "10                   honest wasnt expect much oh god awesome\n",
      "11                                 best product ever use life\n",
      "12             shoe comfortable fit nicely work perfectly jog\n",
      "Name: lemmatized, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    if not isinstance(text, str):  # ✅ Fixed the typo\n",
    "        return \"\"\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    return \" \".join(lemmatized_words)  # Fixed concatenation\n",
    "\n",
    "df[\"lemmatized\"] = df[\"stopwords_removed\"].apply(lemmatize_text)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(df[\"lemmatized\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08a914c1-cabf-4dab-8e67-3279cd9572af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Processed_Reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77123c79-f747-409c-8030-c462a08edc27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
